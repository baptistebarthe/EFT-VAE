{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train_utils import (\n",
    "    VAE_EFT,\n",
    "    find_optimal_latent_dim,\n",
    "    compute_errors,\n",
    "    ROC_curve,\n",
    "    train_with_early_stopping,\n",
    ")\n",
    "\n",
    "M_Z = 91.1876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_ll            69489\n",
       "m_jj            69489\n",
       "pt_l1           69489\n",
       "pt_l2           69489\n",
       "pt_j1           69489\n",
       "pt_j2           69489\n",
       "pt_ll           69489\n",
       "eta_l1          69489\n",
       "eta_l2          69489\n",
       "eta_j1          69489\n",
       "eta_j2          69489\n",
       "delta_eta_jj    69489\n",
       "delta_phi_jj    69489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./data/SM_100k.csv\")\n",
    "# Apply cuts\n",
    "df = dataset[\n",
    "    (abs(dataset[\"m_ll\"] - M_Z) < 15)\n",
    "    & (dataset[\"m_jj\"] > 300)\n",
    "    & (abs(dataset[\"delta_eta_jj\"]) > 2.5)\n",
    "]\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables\n",
    "selection = [\n",
    "    \"m_ll\",\n",
    "    \"m_jj\",\n",
    "    \"pt_l1\",\n",
    "    \"pt_l2\",\n",
    "    \"pt_j1\",\n",
    "    \"pt_j2\",\n",
    "    \"pt_ll\",\n",
    "    \"eta_l1\",\n",
    "    \"eta_l2\",\n",
    "    \"eta_j1\",\n",
    "    \"eta_j2\",\n",
    "    \"delta_eta_jj\",\n",
    "    \"delta_phi_jj\",\n",
    "]\n",
    "df = df[selection]\n",
    "for vars in [\"m_ll\", \"m_jj\", \"pt_l1\", \"pt_l2\", \"pt_j1\", \"pt_j2\", \"pt_ll\"]:\n",
    "    df[vars] = df[vars].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2)\n",
    "X_train, X_valid = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaling\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "X_valid = t.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test dataloaders\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(dataset=X_train, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=X_test, batch_size=batch_size)\n",
    "valid_loader = DataLoader(dataset=X_valid, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EPOCH 0 ===\n",
      "Training loss: 8.19e+00, 7.04e-05\n",
      "Validation loss: 8.07e+00, 9.25e-05\n",
      "=== EPOCH 1 ===\n",
      "Training loss: 8.04e+00, 8.52e-05\n",
      "Validation loss: 7.95e+00, 9.54e-05\n",
      "=== EPOCH 2 ===\n",
      "Training loss: 7.94e+00, 8.84e-05\n",
      "Validation loss: 7.93e+00, 7.86e-05\n",
      "=== EPOCH 3 ===\n",
      "Training loss: 7.90e+00, 8.09e-05\n",
      "Validation loss: 7.86e+00, 8.28e-05\n",
      "=== EPOCH 4 ===\n",
      "Training loss: 7.85e+00, 8.12e-05\n",
      "Validation loss: 7.85e+00, 8.13e-05\n",
      "=== EPOCH 5 ===\n",
      "Training loss: 7.84e+00, 7.74e-05\n",
      "Validation loss: 7.84e+00, 7.23e-05\n",
      "=== EPOCH 6 ===\n",
      "Training loss: 7.83e+00, 7.57e-05\n",
      "Validation loss: 7.81e+00, 7.97e-05\n",
      "=== EPOCH 7 ===\n",
      "Training loss: 7.80e+00, 7.56e-05\n",
      "Validation loss: 7.80e+00, 7.17e-05\n",
      "=== EPOCH 8 ===\n",
      "Training loss: 7.79e+00, 6.87e-05\n",
      "Validation loss: 7.78e+00, 7.24e-05\n",
      "=== EPOCH 9 ===\n",
      "Training loss: 7.78e+00, 7.22e-05\n",
      "Validation loss: 7.77e+00, 6.75e-05\n",
      "=== EPOCH 10 ===\n",
      "Training loss: 7.77e+00, 6.80e-05\n",
      "Validation loss: 7.79e+00, 7.20e-05\n",
      "=== EPOCH 11 ===\n",
      "Training loss: 7.77e+00, 6.77e-05\n",
      "Validation loss: 7.77e+00, 6.76e-05\n",
      "=== EPOCH 12 ===\n",
      "Training loss: 7.75e+00, 6.62e-05\n",
      "Validation loss: 7.74e+00, 6.46e-05\n",
      "=== EPOCH 13 ===\n",
      "Training loss: 7.74e+00, 6.44e-05\n",
      "Validation loss: 7.74e+00, 6.86e-05\n",
      "=== EPOCH 14 ===\n",
      "Training loss: 7.73e+00, 6.33e-05\n",
      "Validation loss: 7.73e+00, 6.26e-05\n",
      "=== EPOCH 15 ===\n",
      "Training loss: 7.71e+00, 6.27e-05\n",
      "Validation loss: 7.71e+00, 6.29e-05\n",
      "=== EPOCH 16 ===\n",
      "Training loss: 7.70e+00, 6.13e-05\n",
      "Validation loss: 7.70e+00, 6.28e-05\n",
      "=== EPOCH 17 ===\n",
      "Training loss: 7.70e+00, 6.10e-05\n",
      "Validation loss: 7.69e+00, 5.99e-05\n",
      "=== EPOCH 18 ===\n",
      "Training loss: 7.70e+00, 6.05e-05\n",
      "Validation loss: 7.70e+00, 6.20e-05\n",
      "=== EPOCH 19 ===\n",
      "Training loss: 7.70e+00, 5.96e-05\n",
      "Validation loss: 7.70e+00, 6.23e-05\n",
      "=== EPOCH 20 ===\n",
      "Training loss: 7.70e+00, 5.94e-05\n",
      "Validation loss: 7.70e+00, 5.65e-05\n",
      "=== EPOCH 21 ===\n",
      "Training loss: 7.70e+00, 5.98e-05\n",
      "Validation loss: 7.69e+00, 5.97e-05\n",
      "=== EPOCH 22 ===\n",
      "Training loss: 7.70e+00, 6.03e-05\n",
      "Validation loss: 7.69e+00, 6.12e-05\n",
      "\n",
      "Early stopping triggered! Best epoch was 17 with loss 7.6936e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " 7.693613755685191,\n",
       " [8.074785459652816,\n",
       "  7.954852456544578,\n",
       "  7.926547638696628,\n",
       "  7.863202182169654,\n",
       "  7.851895946776343,\n",
       "  7.839263036304742,\n",
       "  7.809954918826993,\n",
       "  7.803728455519532,\n",
       "  7.779602137829755,\n",
       "  7.770687249631796,\n",
       "  7.785743110517463,\n",
       "  7.769460087836708,\n",
       "  7.740938469582452,\n",
       "  7.741780721296167,\n",
       "  7.733222281273443,\n",
       "  7.709460833571355,\n",
       "  7.7004190145237095,\n",
       "  7.693613755685191,\n",
       "  7.703255670650654,\n",
       "  7.6970931572405155,\n",
       "  7.700410294914331,\n",
       "  7.695030946569582,\n",
       "  7.6939261614351615])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE_EFT(latent_dim=8).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "train_with_early_stopping(model, train_loader, valid_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing test data (sm vs bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/SM_10k.csv\")\n",
    "\n",
    "# Apply cuts\n",
    "df = dataset[\n",
    "    (abs(dataset[\"m_ll\"] - M_Z) < 15)\n",
    "    & (dataset[\"m_jj\"] > 300)\n",
    "    & (abs(dataset[\"delta_eta_jj\"]) > 2.5)\n",
    "]\n",
    "\n",
    "df = df[selection]\n",
    "for vars in [\"m_ll\", \"m_jj\", \"pt_l1\", \"pt_l2\", \"pt_j1\", \"pt_j2\", \"pt_ll\"]:\n",
    "    df[vars] = df[vars].apply(np.log10)\n",
    "\n",
    "X_sm = t.transform(df)\n",
    "\n",
    "model.eval()\n",
    "T_sm = torch.from_numpy(X_sm).float().to(device)\n",
    "X_sm_hat, mean, log_var = model.forward(T_sm)\n",
    "X_sm_hat = X_sm_hat.detach().cpu()\n",
    "print(T_sm.size(), X_sm_hat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pd.read_csv(\"./data/SM_10k.csv\")\n",
    "o1 = pd.read_csv(\"./data/cW_1_10k.csv\")\n",
    "o2 = pd.read_csv(\"./data/cW_2_10k.csv\")\n",
    "\n",
    "bsm = pd.concat([o1, o2], axis=0)\n",
    "\n",
    "# Apply cuts\n",
    "sm = sm[\n",
    "    (abs(sm[\"m_ll\"] - M_Z) < 15) & (sm[\"m_jj\"] > 300) & (abs(sm[\"delta_eta_jj\"]) > 2.5)\n",
    "]\n",
    "bsm = bsm[\n",
    "    (abs(bsm[\"m_ll\"] - M_Z) < 15)\n",
    "    & (bsm[\"m_jj\"] > 300)\n",
    "    & (abs(bsm[\"delta_eta_jj\"]) > 2.5)\n",
    "]\n",
    "\n",
    "sm = sm[selection]\n",
    "for vars in [\"m_ll\", \"m_jj\", \"pt_l1\", \"pt_l2\", \"pt_j1\", \"pt_j2\", \"pt_ll\"]:\n",
    "    sm[vars] = sm[vars].apply(np.log10)\n",
    "\n",
    "bsm = bsm[selection]\n",
    "for vars in [\"m_ll\", \"m_jj\", \"pt_l1\", \"pt_l2\", \"pt_j1\", \"pt_j2\", \"pt_ll\"]:\n",
    "    bsm[vars] = bsm[vars].apply(np.log10)\n",
    "\n",
    "X_sm = t.transform(sm)\n",
    "T_sm = torch.from_numpy(X_bsm).float().to(device)\n",
    "\n",
    "X_bsm = t.transform(bsm)\n",
    "T_bsm = torch.from_numpy(X_bsm).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_optimal_latent_dim(VAE_EFT, train_loader, valid_loader, device, 12)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
